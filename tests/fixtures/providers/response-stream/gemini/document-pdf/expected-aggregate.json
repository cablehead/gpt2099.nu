{
  "message": {
    "type": "message",
    "role": "assistant",
    "content": [
      {
        "type": "text",
        "text": "gpt2099"
      }
    ],
    "model": "gemini-2.5-flash",
    "usage": {
      "input_tokens": 259,
      "cache_creation_input_tokens": 0,
      "cache_read_input_tokens": 0,
      "output_tokens": 5
    }
  }
}
